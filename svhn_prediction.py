# -*- coding: utf-8 -*-
"""SVHN Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k_qJXPXY5RZs3S18n9TTKVT2KhzydNcE

# Deep Learning with Pytorch: Street View House Number Prediction

# Libraries and Setup

## Import the required Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import cm
from sklearn.model_selection import train_test_split
import torch
import torchvision
from torchvision import transforms, utils
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from collections import Counter
from PIL import Image
from skimage import io, transform
import os
from torchvision.io import read_image
from torch.utils.data import Dataset, DataLoader
from collections import Counter
from google.colab import drive
from prophet import Prophet
from statsmodels.tsa.arima.model import ARIMA

"""## Set up GPU capabilities

The cell below sets up a CUDA device to use with torch, if available to you.


"""

torch.manual_seed(42)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(torch.__version__)
print(device)

device

"""# **Part 1:** Data Preprocessing and Preparation for Modeling in `PyTorch`

The dataset is called Street View House Numbers (or SVHN). The dataset consists of images of **house numbers**, taken from Google Street View. There are 10 classes, one for each digit (0-9).

We would be using this dataset to train 3 different models:

1.   Logistic Regression
2.   Feedforward (Fully-Connected) Neural Network (FNN)
3.   Convolutional Neural Network (CNN)

And analyze the difference between these models by looking at the test accuracy and loss.

## 1.1 Pytorch Dataset

### 1.1.1 Instantiate Dataset (for train/test dataset)

1.   Resize the image to 32 by 32 $\to$ just to make sure they are really have size $32$x$32$
2.   Convert the images to Tensor
3.   Normalize the Tensor using, the means `[0.485, 0.456, 0.406]` and standard deviations `[0.229, 0.224, 0.225]`. We do this because these are color images, and so there are **three** color channels for which we need to normalize (r, g, b).
"""

from torchvision import transforms
scale = 32

transforms = transforms.Compose([
    transforms.Resize([scale, scale]), #resize
    transforms.ToTensor(), #convert to tensor
    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])
    ])

train_dataset = torchvision.datasets.SVHN(root = './data', split = 'train', transform = transforms, download = True)
test_dataset = torchvision.datasets.SVHN(root = './data', split = 'test', transform = transforms, download = True)

print(len(train_dataset))
print(len(test_dataset))

"""## 1.2 Summarizing our Dataset

### 1.2.1 Looking at the distribution of labels
"""

all_train_labels = [label for (_, label) in train_dataset]

train_num_labels = len(set(all_train_labels))

train_dataset_dict = {}
for x in all_train_labels:
  if x in train_dataset_dict:
    train_dataset_dict[x] += 1
  else:
    train_dataset_dict[x] = 1

train_loader_bar_plot = DataLoader(train_dataset, batch_size = len(train_dataset), shuffle = True, num_workers = 0)

print(train_dataset_dict)

all_test_labels = [label for (_, label) in test_dataset]

test_num_labels = len(set(all_test_labels))

test_dataset_dict = {}
for x in all_test_labels:
  if x in test_dataset_dict:
    test_dataset_dict[x] += 1
  else:
    test_dataset_dict[x] = 1

test_loader_bar_plot = DataLoader(test_dataset, batch_size = len(test_dataset), shuffle = True, num_workers = 0)

print(test_dataset_dict)

"""### 1.2.2 Visualize through bar charts


"""

data = pd.DataFrame(list(train_dataset_dict.items()), columns = ['Label', 'Frequency'])
plt.figure(figsize=(8, 6))
ax = sns.barplot(x = 'Label', y = 'Frequency', data = data)
ax.bar_label(ax.containers[0])
plt.title('Training set labels and corresponding frequencies')
plt.xlabel('Labels')
plt.ylabel('Frequency')
plt.show()

data = pd.DataFrame(list(test_dataset_dict.items()), columns = ['Label', 'Frequency'])
plt.figure(figsize=(8, 6))
ax = sns.barplot(x = 'Label', y = 'Frequency', data = data)
ax.bar_label(ax.containers[0])
plt.title('Testing set labels and corresponding frequencies')
plt.xlabel('Labels')
plt.ylabel('Frequency')
plt.show()

"""### 1.2.3 Have equal spread of labels



"""

torch.manual_seed(42)

train_indices = []

train_count_dict = {label: 0 for label in range(10)}

for idx, (image, label) in enumerate(train_dataset):
  if (train_count_dict[label] < 3000):
    train_count_dict[label] += 1
    train_indices.append(idx)

torch.manual_seed(42)

test_indices = []

test_count_dict = {label: 0 for label in range(10)}

for idx, (image, label) in enumerate(test_dataset):
  if (test_count_dict[label] < 500):
    test_count_dict[label] += 1
    test_indices.append(idx)

from torch.utils.data import Subset
train_subset = Subset(train_dataset, train_indices)
test_subset = Subset(test_dataset, test_indices)

train_subset_dict = dict()
test_subset_dict = dict()

for (_, label) in train_subset:
  if label in train_subset_dict:
    train_subset_dict[label] += 1
  else:
    train_subset_dict[label] = 1

for (_, label) in test_subset:
  if label in test_subset_dict:
    test_subset_dict[label] += 1
  else:
    test_subset_dict[label] = 1

batch = 64

train_loader = DataLoader(train_subset, batch_size = batch, shuffle = True, num_workers = 0)
test_loader = DataLoader(test_subset, batch_size = batch, shuffle = True, num_workers = 0)

"""# **Part 2:** Classification Models

## 2.1 Multimonial Logical Logistic Regression - Baseline

### 2.1.1 Logistic Regression Model Architecture
"""

class LogReg(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.weight = nn.Linear(3072, 10)

    def forward(self, x):
        x = self.flatten(x)
        outputs = self.weight(x)
        return outputs

LogReg()

"""### 2.1.2 Training Logistic Regression Model

"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# logreg = LogReg().to(device='cuda:0')
# criterion = nn.CrossEntropyLoss()
# 
# optimizer = optim.Adam(logreg.parameters(), lr=1e-4) #lr - learning step
# epoch = 10
# 
# loss_LIST_log = []
# acc_LIST_log = []
# 
# for epoch in range(epoch):
#   running_loss = 0.0
#   correct = 0
#   total = 0
#   for inputs, labels in train_loader:
#       labels = labels.type(torch.LongTensor) # Cast to Float
#       inputs, labels = inputs.to(device), labels.to(device)
# 
#       optimizer.zero_grad()
#       outputs = logreg(inputs)
#       predicted = outputs.argmax(dim=1)
#       loss = criterion(outputs, labels)
#       loss.backward()
#       optimizer.step()
#       running_loss += loss.item()
#       total += labels.size(0)
#       correct += (predicted == labels).sum().item()
# 
#   accuracy = 100 * correct / total
#   acc_LIST_log.append(accuracy)
#   epoch_loss = running_loss / len(train_loader)
#   loss_LIST_log.append(epoch_loss)
# 
#   print("The loss for Epoch {} is: {}, Accuracy = {}".format(epoch, running_loss/len(train_loader), accuracy))

"""### 2.1.3 Plotting Training Accuracy vs Epochs for Logistic Regression

"""

import matplotlib.pyplot as plt
import seaborn as sns


df = pd.DataFrame(acc_LIST_log, columns = ['accuracy'])

plt.figure(figsize=(5, 3))
sns.lineplot(x = range(1, 11), y = 'accuracy', data = df)
plt.xticks(range(1, 11))
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training Accuracy vs Epochs for Logistic Regression')

"""### 2.1.4 Logistic Regression Model Accuracy

"""

total = 0
correct = 0
with torch.no_grad():
    for images, labels in test_loader:
        labels = labels.type(torch.LongTensor) # Cast to Float
        images, labels = images.to(device), labels.to(device)

        outputs = logreg(images)
        predicted = outputs.argmax(dim = 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

test_acc_log = torch.tensor(100 * correct / total)

print('Test Accuracy: ' + str(test_acc_log.item()))

"""## 2.2 Feedforward Neural Networks

### 2.2.1 Feedforward Neural Network Model Architecture
"""

def raw_sample_to_red(sample):
  # convert an input tensor of shape (batch_size, 3, 32, 32) to just contain the red values
  return sample[:, 0, :, :].unsqueeze(1)
  pass

def raw_sample_to_grayscale(sample):
  # convert an input tensor of shape (batch_size, 3, 32, 32) to just contain the grey scale values
  return sample.mean(dim = 1).unsqueeze(1)
  pass

"""### 2.2.2 Feedforward Neural Network Model Architecture



"""

class FNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.linear1 = nn.Linear(1024, 256)
        self.relu = nn.ReLU()
        self.linear2 = nn.Linear(256, 10)

    def forward(self, x):
        x = self.flatten(x)
        hidden_feat = self.relu(self.linear1(x))
        outputs = self.linear2(hidden_feat)

        return outputs

FNN()

"""### 2.2.3 Training FNN Model

"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# 
# fnn_red = FNN().to(device)
# criterion = nn.CrossEntropyLoss()
# optimizer = optim.Adam(fnn_red.parameters(), lr=1e-4) #lr - learning step
# epoch = 10
# 
# acc_LIST_FNN_red = []
# loss_LIST_FNN_red = []
# 
# for epoch in range(epoch):
#   running_loss = 0.0
#   correct = 0
#   total = 0
#   for inputs, labels in train_loader:
#       labels = labels.type(torch.LongTensor) # Cast to Long
#       inputs, labels = inputs.to(device), labels.to(device)
# 
#       optimizer.zero_grad()
#       outputs = fnn_red(raw_sample_to_red(inputs))
#       predicted = outputs.argmax(dim = 1)
#       loss = criterion(outputs, labels)
#       loss.backward()
#       optimizer.step()
#       running_loss += loss.item()
#       total += labels.size(0)
#       correct += (predicted == labels).sum().item()
# 
#   accuracy = 100 * correct / total
#   acc_LIST_FNN_red.append(accuracy)
#   epoch_loss = running_loss / len(train_loader)
#   loss_LIST_FNN_red.append(epoch_loss)
# 
#   print("The loss for Epoch {} is: {}, Accuracy = {}".format(epoch, running_loss/len(train_loader), accuracy))
# 
#

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# fnn_gray = FNN().to(device)
# criterion = nn.CrossEntropyLoss()
# optimizer = optim.Adam(fnn_gray.parameters(), lr=1e-4) #lr - learning step
# epoch = 10
# 
# acc_LIST_FNN_gray = []
# loss_LIST_FNN_gray = []
# 
# for epoch in range(epoch):
#   running_loss = 0.0
#   correct = 0
#   total = 0
#   for inputs, labels in train_loader:
#       labels = labels.type(torch.LongTensor) # Cast to Long
#       inputs, labels = inputs.to(device), labels.to(device)
# 
#       optimizer.zero_grad()
#       outputs = fnn_gray(raw_sample_to_grayscale(inputs))
#       predicted = outputs.argmax(dim = 1)
#       loss = criterion(outputs, labels)
#       loss.backward()
#       optimizer.step()
#       running_loss += loss.item()
#       total += labels.size(0)
#       correct += (predicted == labels).sum().item()
# 
#   accuracy = 100 * correct / total
#   acc_LIST_FNN_gray.append(accuracy)
#   epoch_loss = running_loss / len(train_loader)
#   loss_LIST_FNN_gray.append(epoch_loss)
# 
#   print("The loss for Epoch {} is: {}, Accuracy = {}".format(epoch, running_loss/len(train_loader), accuracy))

"""### 2.2.4 Feed Forward Network on Raw Inputs Architecture

"""

class FNN_RAW(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.linear1 = nn.Linear(3072, 256)
        self.relu = nn.ReLU()
        self.linear2 = nn.Linear(256, 10)

    def forward(self, x):
        x = self.flatten(x)
        hidden_feat = self.relu(self.linear1(x))
        outputs = self.linear2(hidden_feat)

        return outputs

FNN_RAW()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# fnn = FNN_RAW().to(device)
# criterion = nn.CrossEntropyLoss()
# optimizer = optim.Adam(fnn.parameters(), lr=1e-4)
# epoch = 10
# 
# acc_LIST_FNN = []
# loss_LIST_FNN = []
# 
# for epoch in range(epoch):
#   running_loss = 0.0
#   correct = 0
#   total = 0
#   for inputs, labels in train_loader:
#       labels = labels.type(torch.LongTensor) # Cast to Long
#       inputs, labels = inputs.to(device), labels.to(device)
# 
#       optimizer.zero_grad()
#       outputs = fnn(inputs)
#       predicted = outputs.argmax(dim = 1)
#       loss = criterion(outputs, labels)
#       loss.backward()
#       optimizer.step()
#       running_loss += loss.item()
#       total += labels.size(0)
#       correct += (predicted == labels).sum().item()
# 
#   accuracy = 100 * correct / total
#   acc_LIST_FNN.append(accuracy)
#   epoch_loss = running_loss / len(train_loader)
#   loss_LIST_FNN.append(epoch_loss)
# 
#   print("The loss for Epoch {} is: {}, Accuracy = {}".format(epoch, running_loss/len(train_loader), accuracy))

"""### 2.2.5 Plotting Training Accuracy vs Epochs FNN


"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5, 3))
df = pd.DataFrame({'red_accuracy': acc_LIST_FNN_red, 'grayscale_accuracy': acc_LIST_FNN_gray, 'raw_accuracy': acc_LIST_FNN})
x_range = range(1, 11)
sns.lineplot(x = x_range, y = 'red_accuracy', data = df, label = 'Red')
sns.lineplot(x = x_range, y = 'grayscale_accuracy', data = df, label = 'Grayscale')
sns.lineplot(x = x_range, y = 'raw_accuracy', data = df, label = 'Raw')
plt.legend(title = 'FNN model')
plt.xticks(x_range)
plt.title('Training Accuracy vs Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.show()

"""### 2.2.6 FNN Model Accuracy

"""

total = 0
correct_fnn = 0
correct_fnn_red = 0
correct_fnn_gray = 0
with torch.no_grad():
    for images, labels in test_loader:
        labels = labels.type(torch.LongTensor) # Cast to Float
        images, labels = images.to(device), labels.to(device)

        outputs_red = fnn_red(raw_sample_to_red(images))
        outputs_gray = fnn_gray(raw_sample_to_grayscale(images))
        outputs_raw = fnn(images)
        # Get the prediction using argmax
        predicted_red = outputs_red.argmax(dim = 1)
        predicted_gray = outputs_gray.argmax(dim = 1)
        predicted_raw = outputs_raw.argmax(dim = 1)
        # Get number of correct prediction and add to correct and total
        total += labels.size(0)
        correct_fnn_red += (predicted_red == labels).sum().item()
        correct_fnn_gray += (predicted_gray == labels).sum().item()
        correct_fnn += (predicted_raw == labels).sum().item()

# Calculate test accuracy for FNN
test_acc_FNN_red = torch.tensor(100 * correct_fnn_red / total)
test_acc_FNN_gray = torch.tensor(100 * correct_fnn_gray / total)
test_acc_FNN = torch.tensor(100 * correct_fnn / total)

print('Test Accuracy (Red Values Only): ' + str(test_acc_FNN_red.item()))
print('Test Accuracy (Grayscale Values Only): ' + str(test_acc_FNN_gray.item()))
print('Test Accuracy (All Values): ' + str(test_acc_FNN.item()))

"""##2.3 Convolutional Neural Networks

### 2.3.0 Calculating Output Dimensions of Convolution and Pooling Layers
"""

import math

def feature_map_dim(input_dim, padding, kernel_size, stride):
  return int((input_dim + (2 * padding) - (kernel_size - 1) - 1) / stride + 1)

"""### 2.3.1 Creating custom Convolutional Neural Network Architecture"""

class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3, stride = 1, padding = 1)
        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)
        self.mp = nn.MaxPool2d(kernel_size=2, stride = 2)
        self.relu = nn.ReLU()
        self.flatten = nn.Flatten(start_dim=1)
        size = feature_map_dim(32, 1, 3, 1)
        size = feature_map_dim(size, 0, 2, 2)
        size = feature_map_dim(size, 1, 3, 1)
        size = feature_map_dim(size, 0, 2, 2)
        self.fc = nn.Linear(32 * size * size, out_features=10)

    def forward(self, x):
      outputs = self.conv(x)
      outputs = self.relu(outputs)
      outputs = self.mp(outputs)
      outputs = self.conv2(outputs)
      outputs = self.relu(outputs)
      outputs = self.mp(outputs)
      outputs = self.flatten(outputs)
      outputs = self.fc(outputs)
      return outputs

CNN()

"""### 2.3.2 Training CNN Model

"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# cnn = CNN().to(device)
# criterion = nn.CrossEntropyLoss()
# optimizer = optim.Adam(cnn.parameters(), lr=1e-4)
# epoch = 10
# 
# acc_LIST_CNN = []
# loss_LIST_CNN = []
# 
# for epoch in range(epoch):
#   running_loss = 0.0
#   correct = 0
#   total = 0
#   for inputs, labels in train_loader:
#       labels = labels.type(torch.LongTensor) # Cast to Float
#       inputs, labels = inputs.to(device), labels.to(device)
#       optimizer.zero_grad()
#       outputs = cnn(inputs)
#       predicted = outputs.argmax(dim = 1)
#       loss = criterion(outputs, labels)
#       loss.backward()
#       optimizer.step()
#       running_loss += loss.item()
#       total += labels.size(0)
#       correct += (predicted == labels).sum().item()
# 
#   accuracy = 100 * correct / total
#   acc_LIST_CNN.append(accuracy)
#   epoch_loss = running_loss / len(train_loader)
#   loss_LIST_CNN.append(epoch_loss)
# 
#   print("The loss for Epoch {} is: {}, Accuracy = {}".format(epoch, running_loss/len(train_loader), accuracy))

"""### 2.3.3 Plotting Training Accuracy vs Epochs CNN


"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize = (5, 3))
x_range = range(1, 11)
sns.lineplot(x = x_range, y = acc_LIST_CNN)

plt.xticks(x_range)
plt.title('Training Accuracy vs Epochs')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')

plt.show()

"""### 2.3.4 CNN Model Test Accuracy


"""

total = 0
correct = 0
with torch.no_grad():
    for images, labels in test_loader:
        labels = labels.type(torch.LongTensor) # Cast to Float
        images, labels = images.to(device), labels.to(device)
        output = cnn(images)
        prediction = output.argmax(dim=1)
        total += labels.size(0)
        correct += (prediction == labels).sum().item()

test_acc_CNN = torch.tensor(100 * correct / total)

print(f'Test Accuracy: ' + str(test_acc_CNN.item()))

"""### 2.3.5 CNN Hyperparameter Tuning

Hyperparameters tuned: `learning rate`, `beta1`, `beta2` and `number of fully connected layers`.

"""

class CNNTuned(nn.Module):
    def __init__(self, ff_layers = 3):
        super().__init__()
        self.num_ff_layers = ff_layers
        self.conv = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 3, stride = 1, padding = 1)
        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)
        self.mp = nn.MaxPool2d(kernel_size=2, stride = 2)
        self.relu = nn.ReLU()
        self.flatten = nn.Flatten(start_dim=1)
        size = feature_map_dim(32, 1, 3, 1)
        size = feature_map_dim(size, 0, 2, 2)
        size = feature_map_dim(size, 1, 3, 1)
        size = feature_map_dim(size, 0, 2, 2)

        flattened_size = 32 * size * size
        self.ff_layers = nn.ModuleList()

        for i in range(self.num_ff_layers - 1):
          self.ff_layers.append(nn.Linear(flattened_size, flattened_size // 2))
          flattened_size = flattened_size // 2
        self.ff_layers.append(nn.Linear(in_features=flattened_size, out_features=10))

    def forward(self, x):
      outputs = self.conv(x)
      outputs = self.relu(outputs)
      outputs = self.mp(outputs)
      outputs = self.conv2(outputs)
      outputs = self.relu(outputs)
      outputs = self.mp(outputs)
      outputs = self.flatten(outputs)

      for i, fc in enumerate(self.ff_layers):
            outputs = fc(outputs)
            if i < self.num_ff_layers - 1:
                outputs = self.relu(outputs)
      return outputs

from sklearn.model_selection import ParameterGrid

param_grid  = {
    'learning_rate': [0.001, 0.0005, 0.0001],
    'betas': [(0.9, 0.999), (0.95, 0.999), (0.9, 0.995)],
    'num_fc' : [1, 2, 3]
}

pgrid = ParameterGrid(param_grid)

num_epochs = 5

def cnn_train_and_evaluate(model, train_loader, optimizer, num_epochs):
  criterion = nn.CrossEntropyLoss()
  best_accuracy = 0
  for epochs in range(num_epochs):
    correct = 0
    total = 0
    for inputs, labels in train_loader:
        labels = labels.type(torch.LongTensor) # Cast to Float
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        predicted = outputs.argmax(dim = 1)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    epoch_accuracy = 100 * correct / total
    if epoch_accuracy > best_accuracy:
          best_accuracy = epoch_accuracy

  return best_accuracy

best_params = None
best_accuracy = 0;

for params in pgrid:
    model = CNNTuned(ff_layers=params['num_fc']).to(device)
    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], betas=params['betas'])
    accuracy = cnn_train_and_evaluate(model, train_loader, optimizer, num_epochs)
    print(str(params) + " accuracy : " + str(accuracy))

    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_params = params

print(best_params)
print(best_accuracy)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# cnn = CNNTuned(ff_layers=best_params['num_fc']).to(device)
# criterion = nn.CrossEntropyLoss()
# optimizer = optim.Adam(cnn.parameters(), lr=best_params['learning_rate'], betas=best_params['betas'])
# epoch = 10
# 
# acc_LIST_CNN_TUNE = []
# loss_LIST_CNN_TUNE = []
# 
# for epoch in range(epoch):
#   running_loss = 0.0
#   correct = 0
#   total = 0
#   for inputs, labels in train_loader:
#       labels = labels.type(torch.LongTensor) # Cast to Float
#       inputs, labels = inputs.to(device), labels.to(device)
#       optimizer.zero_grad()
#       outputs = cnn(inputs)
#       predicted = outputs.argmax(dim = 1)
#       loss = criterion(outputs, labels)
#       loss.backward()
#       optimizer.step()
#       running_loss += loss.item()
#       total += labels.size(0)
#       correct += (predicted == labels).sum().item()
# 
#   accuracy = 100 * correct / total
#   acc_LIST_CNN_TUNE.append(accuracy)
#   epoch_loss = running_loss / len(train_loader)
#   loss_LIST_CNN_TUNE.append(epoch_loss)
# 
#   print("The loss for Epoch {} is: {}, Accuracy = {}".format(epoch, running_loss/len(train_loader), accuracy))

total = 0
correct = 0
with torch.no_grad():
    for images, labels in test_loader:
        labels = labels.type(torch.LongTensor) # Cast to Float
        images, labels = images.to(device), labels.to(device)
        output = cnn(images)
        prediction = output.argmax(dim = 1)
        total += labels.size(0)
        correct += (prediction == labels).sum().item()

test_acc_CNN = torch.tensor(100 * correct / total)

print(f'Test Accuracy: ' + str(test_acc_CNN.item()))

"""## 2.4. Reflection

Let's compare the model performance:

From the test accuracies, we can see that FNN works better than Logistic Regression, and CNN works even better than FNN.
"""

print(f'Test Accuracy for Logistic Regression: ' + str(test_acc_log.item()))
print(f'Test Accuracy for FNN: ' + str(test_acc_FNN.item()))
print(f'Test Accuracy for CNN: ' + str(test_acc_CNN.item()))

"""## 2.5 Confusion Matrix

### 2.5.1 Create confusion matrix
"""

import pandas as pd
import numpy as np
from sklearn.metrics import confusion_matrix

def cm_generator(test_loader):
  model.eval()
  all_preds = []
  all_labels = []

  with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            predicted = outputs.argmax(dim = 1)

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

  cm = confusion_matrix(all_labels, all_preds)

  cm_df = pd.DataFrame(cm)

  return cm_df

confusion_matrix_df = cm_generator(test_loader)

"""### 2.5.2 Visualizing Confusion Matrix

"""

fig = plt.figure(figsize = (8, 4))
sns.heatmap(confusion_matrix_df, annot = True, fmt = "g", cmap = "crest")
plt.title('Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()